# 第二周作业

## 作业一

使用 GCLogAnalysis.java 自己演练一遍串行 / 并行 /CMS/G1 的案例。



以下是5组不同内存下，各垃圾回收器的GC数据：

环境：macpro 2.6GHz 6核 16g内存

*-Xms256m -Xmx256m*

|              | SerialGC | ParallelGC  | ConcMarkSweepGC | G1GC |
| :----------: | :------: | :---------: | :-------------: | :--: |
| 生成对象个数 |   4240   | 3140(或OOM) |      4173       | OOM  |
| YoungGC次数  |    9     |     12      |       11        |      |
|  FullGC次数  |   20+    |     20      |       15        |      |
| YoungGC耗时  |   0.16   |    0.14     |                 |      |
|  FullGC耗时  |   0.6+   |    0.5+     |                 |      |
|    总耗时    |  0.76+   |    0.64+    |                 |      |
| 堆内存使用率 |   100%   |    100%     |      100%       |  -   |

256内存下，几个GC内存使用率都基本打满，ParallelGC甚至OOM，耗时最久的事SerialGC会处于一种一直FULL GC状态，使程序停滞，单位时间内生成的对象SerialGC最高，但相差不大，表现均不好。



*-Xms512m -Xmx512m*

|              | SerialGC | ParallelGC | ConcMarkSweepGC | G1GC |
| :----------: | :------: | :--------: | :-------------: | :--: |
| 生成对象个数 |   8106   |    7314    |      9066       | 9231 |
| YoungGC次数  |    16    |     26     |                 |      |
|  FullGC次数  |    0     |     5      |                 |      |
| YoungGC耗时  |   0.6+   |    0.3     |                 |      |
|  FullGC耗时  |    0     |    0.2     |                 |      |
|    总耗时    |   0.6+   |    0.5     |      0.4+       |      |
| 堆内存使用率 |   95%    |    85%+    |       90%       | 65%  |

512内存下，G1表现最好，生成对象数明显更多，GC时间数更少，ParallelGC耗时小于SerialGC，但生成对象数缺小于SerialGC，整体相差不太多。



*-Xms1g -Xmx1g*

|              | SerialGC | ParallelGC | ConcMarkSweepGC | G1GC  |
| :----------: | :------: | :--------: | :-------------: | :---: |
| 生成对象个数 |  10394   |    9764    |      11613      | 10658 |
| YoungGC次数  |    10    |     14     |        9        |       |
|  FullGC次数  |    0     |     1      |        1        |       |
| YoungGC耗时  |   0.51   |    0.4+    |      0.41       |       |
|  FullGC耗时  |    0     |   0.057    |      0.046      |       |
|    总耗时    |   0.51   |   0.45+    |      0.456      |       |
| 堆内存使用率 |   54%    |    53%+    |       48%       |  58%  |

1G内存下，几个GC回收器所生成的对象差不多，此时ParallelGC和ConcMarkSweepGC的GC总耗时差不多，ParallelGC比上一个阶段（512m内存）有所改善。

*-Xms2g -Xmx2g*

|              | SerialGC | ParallelGC | ConcMarkSweepGC |         G1GC         |
| :----------: | :------: | :--------: | :-------------: | :------------------: |
| 生成对象个数 |  10509   |   11885    |      12228      | 7000-11500（波动大） |
| YoungGC次数  |    5     |     6      |        5        |                      |
|  FullGC次数  |    0     |     0      |        0        |                      |
| YoungGC耗时  |   0.45   |    0.38    |      0.35       |                      |
|  FullGC耗时  |   0.45   |     0      |        0        |                      |
|    总耗时    |   0.45   |    0.38    |      0.35       |         0.24         |
| 堆内存使用率 |   41%    |    43%+    |       42%       |  40～73%（波动大）   |

2g内存下，SerialGC单次GC的耗时最久，整体耗时也是最久的；ParrallelGC单次GC的时间要小于CMSGC，但整体次数要大于CMS，总体耗时与CMS差不多，单位时间生成对象数略小于CMS。整体上讲ParallelGC和ConcMarkSweepGC，在2g内存下生成的对象相差不多，CMSGC耗时总体更少。观测到G1这个解决波动很大，暂不知道原因。



*-Xms4g -Xmx4g*·

|              | SerialGC | ParallelGC | ConcMarkSweepGC | G1GC  |
| :----------: | :------: | :--------: | :-------------: | :---: |
| 生成对象个数 |   8340   |   11345    |      11894      | 10980 |
| YoungGC次数  |    2     |     2      |        4        |       |
|  FullGC次数  |    0     |     0      |        0        |       |
| YoungGC耗时  |   0.3    |    0.2     |      0.30       |       |
|  FullGC耗时  |    0     |     0      |        0        |       |
|    总耗时    |   0.3    |    0.2     |       0.3       | 0.33  |
| 堆内存使用率 |    9%    |     6%     |       15%       |       |

4g内存下，SerialGC单次耗时达到0.15秒，单位时间内生成对象反而下降，总体性能反而下降；ParallelGC单次GC耗时0.1秒，且单位时间内生成的对象明显高于SerialGC；CMSGC单次GC耗时更短，但发生了4次GC，总体耗时反而变长，生成对象与ParallelGC查不多；G1GC由于GC pause多次造成耗时变长。总体上讲，4g内存下ParallelGC无论从生成对象个数来说还是吞吐量来说都更优秀一些。

-------

总结：随着内存的增大，ParallelGC有着更好的吞吐量（GC时间占比少），GC次数少，但单次GC时间变大；虽然CMSGC的吞吐量也在提高，但改善情况不如ParallelGC显著，但是CMSGC单次GC的时间更短，因此会比ParallelGC更快的响应，而SerialGC并没有因为内存的增大生成更多的对象，反而下降了，单次GC时间非常久，造成系统卡顿。



## 作业二

使用压测工具(wrk或sb)，演练gateway-server-0.0.1-SNAPSHOT.jar 示例。

分别测试串行、并行、CMS、G1等GC，内存测试分别为512M、1G、2G、4G、8G。

测试的QPS数据如下：wrk  -c60 -d10s  http://localhost:8088/api/hello

| GC/内存 | 512M     | 1G       | 2G       | 4G       | 8G       |
| ------- | -------- | -------- | -------- | -------- | -------- |
| 串行    | 59405    | 60476.86 | 60821.82 | 58032.76 | 59162.01 |
| 并行    | 63249.90 | 63241    | 63583    | 73028    | 70001.20 |
| CMS     | 64733.32 | 61272.69 | 63991.97 | 65287.30 | 65414.50 |
| G1      | 57162.47 | 60082.11 | 68464.33 | 64612.26 | 55458.85 |

可以看到随着内存的增大，几个GC都是一个先增后减的趋势，并不是内存越大性能越好；串行GC随着内存增性能反而下降；其中并行大内存下，吞吐量更高，G1GC8g内存下性能明显下降。



## 作业三（先跳过）



## 作业四

运行课上的例子，以及Netty的例子，分析相关现象

    测试命令：wrk  -c40 -d60s [http://localhost:8080](http://localhost:8080/) 

    测试数据如下：可以看到性能的提升还是比较明显的

- 单线程版本：11.60
- 多线程版本：45.90
- 线程池版本：22.20（10个线程）23.39（20个线程） 27.56（40个线程）29.20（80个线程）
- netty：100888.50

## 作业五

写一段代码，使用 HttpClient 或 OkHttp 访问[http://localhost:8801，代码提交到](http://localhost:8801，代码提交到/) github

这里使用HttpClient，改写了工作中的一段代码HttpClientDemo。



遇到的问题：

碰到connection reset的错误，跟踪了一下源码SocketInputStream#socketRead(fd, b, off, length, timeout)抛出的异常，Apache的HttpClient中实现方法SessionInputBufferImpl#readLine用了一个while循环来调用socketRead方法，如果不设置长度会一直度，直到socketRead抛异常；原因是服务器没有设置content-length的大小，导致客户端一直在读取缓冲区数据，直到遇到服务器关闭引起的异常错误。

解决办法，添加一行以下代码：

printWriter.println("Content-Length:" + body.getBytes().length);

添加一下依赖

```
<dependency>
    <groupId>org.apache.httpcomponents</groupId>
    <artifactId>httpclient</artifactId>
    <version>4.4.1</version>
</dependency>
```

代码如下：

```java
import org.apache.http.HttpEntity;
import org.apache.http.HttpResponse;
import org.apache.http.HttpStatus;
import org.apache.http.client.HttpClient;
import org.apache.http.client.config.RequestConfig;
import org.apache.http.client.methods.HttpGet;
import org.apache.http.client.methods.HttpRequestBase;
import org.apache.http.impl.client.CloseableHttpClient;
import org.apache.http.impl.client.HttpClients;
import org.apache.http.impl.conn.PoolingHttpClientConnectionManager;
import org.apache.http.util.EntityUtils;

import java.io.IOException;


/**
 * @author Lijiajun
 * @date 2020/10/28 10:51
 */
public class HttpClientDemo {

    private HttpClient httpClient;
    
    public HttpClientDemo() {
        httpClient = HttpConnectManager.getHttpClient();
    }

    private String sendRequest(HttpRequestBase httpRequest) {
        String res;
        HttpResponse response;
        HttpEntity entity;
        try {
            response = httpClient.execute(httpRequest);
            entity = response.getEntity();

            if (response.getStatusLine().getStatusCode() == HttpStatus.SC_OK) {
                res = entity != null ? EntityUtils.toString(entity, "utf-8") : "";
                return res;
            }
            throw new RuntimeException("Http状态码错误");
        } catch (IOException e) {
            e.printStackTrace();
            throw new RuntimeException("IO异常" + e.getMessage());
        } finally {
            httpRequest.releaseConnection();
        }
    }


    public static String HOST = "http://localhost:8801";
    public static void main(String[] args) {
        HttpClientDemo httpClientDemo = new HttpClientDemo();
        HttpGet httpGet = new HttpGet(HOST);
        try {
            String s = httpClientDemo.sendRequest(httpGet);
            System.out.println(s);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }


    static class HttpConnectManager {
        private static PoolingHttpClientConnectionManager cm;
        /**
         * 最大连接数
         */
        public final static int MAX_TOTAL_CONNECTIONS = 500;

        /**
         * 每个路由最大连接数
         */
        public final static int MAX_ROUTE_CONNECTIONS = 300;
        static {
            cm = new PoolingHttpClientConnectionManager();
            cm.setMaxTotal(MAX_TOTAL_CONNECTIONS);

            cm.setDefaultMaxPerRoute(MAX_ROUTE_CONNECTIONS);
        }
        public static CloseableHttpClient getHttpClient() {
            //设置默认时间
            RequestConfig params = RequestConfig.custom().setConnectTimeout(10000).setConnectionRequestTimeout(10000).setSocketTimeout(10000)
                    .setExpectContinueEnabled(true).build();

            return HttpClients.custom()
                    .setConnectionManager(cm)
                    .setDefaultRequestConfig(params)
                    .build();
        }
    }

}

```
